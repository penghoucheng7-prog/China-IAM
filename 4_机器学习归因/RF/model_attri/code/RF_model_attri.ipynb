{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290f04af-a45b-4a8c-ae6e-b891be3b7b44",
   "metadata": {},
   "source": [
    "# æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ada4b-0d86-4786-82b9-30e2133642e9",
   "metadata": {},
   "source": [
    "## å¾®è°ƒåœ°åŒº+æ¨¡å‹+Morris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace584cf-8c6b-415a-aff4-a21ecb7f8cba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ä¿®æ”¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549daaa6-b8ac-451b-ba9c-7f33bc47df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os, re, psutil, shap, matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from interpret.blackbox import MorrisSensitivity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score,\n",
    "    mean_squared_error, mean_absolute_error, median_absolute_error\n",
    ")\n",
    "import matplotlib\n",
    "\n",
    "# â€”â€” å­—ä½“é…ç½®ï¼šå®‹ä½“ + Times â€”â€”\n",
    "config = {\n",
    "    \"font.family\": 'serif',\n",
    "    \"font.serif\": ['SimSun'],\n",
    "    \"mathtext.fontset\": 'stix',\n",
    "    \"font.size\": 12,\n",
    "    \"axes.unicode_minus\": False\n",
    "}\n",
    "matplotlib.rcParams.update(config)\n",
    "\n",
    "# â€”â€” è·¯å¾„é…ç½® â€”â€”\n",
    "INPUT = r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\data\\var_attri_data_interp_cleaned.csv\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def sanitize(s):\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', s)\n",
    "\n",
    "def check_memory(gb=1):\n",
    "    avail = psutil.virtual_memory().available / (1024**3)\n",
    "    if avail < gb:\n",
    "        raise MemoryError(f\"å†…å­˜ä¸è¶³: {avail:.2f}â€¯GB\")\n",
    "        \n",
    "def analyze(var, df, output_dir, fine_tune_regions=[\"CHN\",\"R10CHINA+\"], target_model=None):\n",
    "    id_cols = ['Model','Scenario','Region','Year', var]\n",
    "    vars_cols = [\n",
    "        c for c in df.columns\n",
    "        if c not in id_cols and var not in c\n",
    "    ]\n",
    "    data = df[id_cols + vars_cols].dropna()\n",
    "\n",
    "    # â€”â€” æ¨¡å‹å­æ ·æœ¬ç­›é€‰ â€”â€”\n",
    "    if target_model is not None:\n",
    "        data = data[data['Model'] == target_model]\n",
    "        print(f\"[âˆš] ä»…é’ˆå¯¹æ¨¡å‹ {target_model} è¿›è¡Œå­æ ·æœ¬åˆ†æï¼Œæ ·æœ¬é‡: {len(data)}\")\n",
    "        if data.empty:\n",
    "            print(f\"[!] æœªæ‰¾åˆ°æ¨¡å‹ {target_model} çš„æ•°æ®ï¼Œè·³è¿‡ã€‚\")\n",
    "            return\n",
    "\n",
    "    X, y = data[vars_cols], data[var].values\n",
    "\n",
    "    # â€”â€” ä»…é’ˆå¯¹ fine_tune_regions ç­›é€‰\n",
    "    mask = data['Region'].isin(fine_tune_regions)\n",
    "    X_sub, y_sub = X[mask], y[mask]\n",
    "\n",
    "    # â€”â€” æ¨¡å‹: RandomForest â€”â€”\n",
    "    et = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        min_samples_leaf=4,\n",
    "        max_features=\"sqrt\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    et.fit(X_sub, y_sub)\n",
    "\n",
    "    check_memory()\n",
    "\n",
    "    # â€”â€”â€” æ€§èƒ½è¯„ä¼°\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X_sub, y_sub, test_size=0.3, random_state=42)\n",
    "    preds_te = et.predict(Xte)\n",
    "    metrics = {\n",
    "        \"R2_in\": r2_score(ytr, et.predict(Xtr)),\n",
    "        \"R2_out\": r2_score(yte, preds_te),\n",
    "        \"EVS_out\": explained_variance_score(yte, preds_te),\n",
    "        \"MSE_out\": mean_squared_error(yte, preds_te),\n",
    "        \"MAE_out\": mean_absolute_error(yte, preds_te),\n",
    "        \"MedAE_out\": median_absolute_error(yte, preds_te),\n",
    "    }\n",
    "    tag = sanitize(var)\n",
    "    outdir = os.path.join(output_dir, tag + (f\"_model_{sanitize(target_model)}\" if target_model else \"\"))\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    pd.DataFrame([metrics]).to_csv(\n",
    "        os.path.join(outdir, f\"{tag}_æ¨¡å‹æŒ‡æ ‡.csv\"),\n",
    "        index=False, encoding='utf-8-sig'\n",
    "    )\n",
    "\n",
    "    # â€”â€”â€” ç‰¹å¾é‡è¦æ€§\n",
    "    imp = et.feature_importances_\n",
    "    imp_df = pd.DataFrame({\n",
    "        \"å˜é‡\": vars_cols,\n",
    "        \"ç›¸å¯¹é‡è¦æ€§(%)\": np.round(imp / imp.sum() * 100, 4)\n",
    "    }).nlargest(10, \"ç›¸å¯¹é‡è¦æ€§(%)\")\n",
    "    imp_df.to_csv(\n",
    "        os.path.join(outdir, f\"{tag}_å˜é‡ç›¸å¯¹é‡è¦æ€§.csv\"),\n",
    "        index=False, encoding='utf-8-sig'\n",
    "    )\n",
    "\n",
    "    # â€”â€”â€” SHAP åˆ†æ\n",
    "    sample = X_sub.sample(n=min(100, len(X_sub)), random_state=42)\n",
    "    expl = shap.TreeExplainer(et)\n",
    "    shap_vals = expl.shap_values(sample)\n",
    "\n",
    "    top_feats = imp_df[\"å˜é‡\"].tolist()\n",
    "    top_idx = [sample.columns.get_loc(f) for f in top_feats]\n",
    "\n",
    "    shap.summary_plot(\n",
    "        shap_vals[:, top_idx],\n",
    "        sample[top_feats],\n",
    "        feature_names=top_feats,\n",
    "        show=False, max_display=10\n",
    "    )\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.axes[0]; ax.set_xlabel(\"\"); ax.set_ylabel(\"\")\n",
    "    cbar = fig.axes[-1]; cbar.set_ylabel(\"\"); cbar.set_yticklabels([]); cbar.set_xticklabels([])\n",
    "\n",
    "    mean_shap = np.abs(shap_vals[:, top_idx]).mean(axis=0)\n",
    "    ordered_idx = np.argsort(mean_shap)[::-1]\n",
    "    for y_loc, idx in enumerate(ordered_idx):\n",
    "        mv = mean_shap[idx]\n",
    "        ax.hlines(y=y_loc, xmin=mv - 0.01, xmax=mv + 0.01,\n",
    "                  color=\"black\", linewidth=12, zorder=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{tag}_SHAP.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    pd.DataFrame({\n",
    "        \"å˜é‡\": [top_feats[i] for i in ordered_idx],\n",
    "        \"SHAPå‡å€¼\": np.round(mean_shap[ordered_idx], 6)\n",
    "    }).to_csv(\n",
    "        os.path.join(outdir, f\"{tag}_mean_SHAP.csv\"),\n",
    "        index=False, encoding='utf-8-sig'\n",
    "    )\n",
    "\n",
    "    mean_shap_df = pd.DataFrame({\n",
    "        \"å˜é‡\": [top_feats[i] for i in ordered_idx],\n",
    "        \"å‡å€¼_SHAP\": np.round(mean_shap[ordered_idx], 6),\n",
    "        \"ç‰¹å¾é‡è¦æ€§\": np.round(imp_df[\"ç›¸å¯¹é‡è¦æ€§(%)\"].values[ordered_idx] / 100, 6),\n",
    "        \"SHAP_æ ‡å‡†å·®\": np.round(np.std(shap_vals[:, top_idx][:, ordered_idx], axis=0), 6)\n",
    "    })\n",
    "    mean_shap_df.to_csv(os.path.join(outdir, f\"{tag}_SHAP_vs_Imp.csv\"),\n",
    "                        index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # ğŸ“Š å›¾1. SHAP vs ç‰¹å¾é‡è¦æ€§æŸ±çŠ¶å›¾\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    df_plot = mean_shap_df.sort_values(\"å‡å€¼_SHAP\", ascending=True)\n",
    "    y = np.arange(len(df_plot))\n",
    "    ax.barh(y - 0.2, df_plot[\"å‡å€¼_SHAP\"], height=0.4, label=\"SHAPå‡å€¼\")\n",
    "    ax.barh(y + 0.2, df_plot[\"ç‰¹å¾é‡è¦æ€§\"], height=0.4, label=\"ç‰¹å¾é‡è¦æ€§\")\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(df_plot[\"å˜é‡\"])\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{tag}_SHAP_vs_Imp_bar.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # ğŸ“ˆ å›¾2. Morris Âµ* vs Ïƒ æ•£ç‚¹å›¾\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    sc = ax.scatter(\n",
    "        mean_shap_df[\"å‡å€¼_SHAP\"],\n",
    "        mean_shap_df[\"SHAP_æ ‡å‡†å·®\"],\n",
    "        s=100 * mean_shap_df[\"ç‰¹å¾é‡è¦æ€§\"],\n",
    "        c=mean_shap_df[\"ç‰¹å¾é‡è¦æ€§\"],\n",
    "        cmap=\"viridis\",\n",
    "        alpha=0.8,\n",
    "        edgecolors='k'\n",
    "    )\n",
    "    for _, row in mean_shap_df.iterrows():\n",
    "        ax.text(row[\"å‡å€¼_SHAP\"], row[\"SHAP_æ ‡å‡†å·®\"], row[\"å˜é‡\"], fontsize=8)\n",
    "    ax.set_xlabel(\"Morris Âµ* (SHAPå‡å€¼)\")\n",
    "    ax.set_ylabel(\"Ïƒ (SHAPæ ‡å‡†å·®)\")\n",
    "    plt.colorbar(sc, label=\"ç‰¹å¾é‡è¦æ€§\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(outdir, f\"{tag}_Morris_scatter.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # ğŸ“‰ å›¾3. SHAP Dependence Plotï¼ˆå‰ 3 ä¸ªå˜é‡ï¼‰\n",
    "    for i, feat in enumerate([top_feats[i] for i in ordered_idx[:3]]):\n",
    "        interaction_index = 'auto'\n",
    "        if interaction_index == 'auto':\n",
    "            interactions = shap.utils.approximate_interactions(\n",
    "                feat, shap_vals, sample\n",
    "            )\n",
    "            interaction_feat = sample.columns[interactions[0]]\n",
    "        else:\n",
    "            interaction_feat = interaction_index\n",
    "\n",
    "        x = sample[feat].values\n",
    "        y_ = shap_vals[:, sample.columns.get_loc(feat)]\n",
    "        color = sample[interaction_feat].values if interaction_feat != feat else None\n",
    "\n",
    "        shap.dependence_plot(\n",
    "            sample.columns.get_loc(feat), shap_vals, sample,\n",
    "            feature_names=sample.columns.tolist(),\n",
    "            interaction_index=interaction_index, show=False\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        png_path = os.path.join(outdir, f\"{tag}_SHAP_dependence_{sanitize(feat)}.png\")\n",
    "        plt.savefig(png_path, dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        data = {\n",
    "            feat: x,\n",
    "            f\"SHAP_{feat}\": y_,\n",
    "        }\n",
    "        if color is not None:\n",
    "            data[interaction_feat] = color\n",
    "        df_dep = pd.DataFrame(data)\n",
    "        csv_path = os.path.join(outdir, f\"{tag}_SHAP_dependence_{sanitize(feat)}.csv\")\n",
    "        df_dep.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"[âœ”] {var} ä½¿ç”¨ RandomForest åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š{outdir}\")\n",
    "\n",
    "# ========== ç”¨æ³•ç¤ºä¾‹ ==========\n",
    "# df = pd.read_csv(INPUT)\n",
    "# analyze('YourVariable', df, OUTPUT_DIR, target_model='GCAM5.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd413aeb-971c-4a99-bae9-a72d2932e8ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sobol æ¼æ–—å¼éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49a13c6-0906-42fa-9eb2-62fb4fca7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.sample import saltelli\n",
    "from SALib.analyze import sobol\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd, numpy as np, os\n",
    "\n",
    "def run_sobol_analysis(X, y, var_names, output_dir, tag=\"fei\", target_model=None):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X[var_names])\n",
    "\n",
    "    problem = {\n",
    "        'num_vars': len(var_names),\n",
    "        'names': var_names,\n",
    "        'bounds': [[0, 1]] * len(var_names)\n",
    "    }\n",
    "\n",
    "    # é‡‡æ · + æ¨¡æ‹Ÿ\n",
    "    param_values = saltelli.sample(problem, 512, calc_second_order=True)\n",
    "    # === æ›¿æ¢ä¸º RandomForestRegressor ===\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        min_samples_leaf=4,\n",
    "        max_features=\"sqrt\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_scaled, y)\n",
    "    # æ³¨æ„ï¼šéšæœºæ£®æ—ä¸æ”¯æŒç›´æ¥è¶…èŒƒå›´å¤–æ¨, è¿™é‡Œåªæ˜¯æ¼”ç¤ºï¼›å®é™…sobolé‡‡æ ·å¤–æ¨å¯èƒ½æœ‰è¯¯å·®\n",
    "    Y = model.predict(param_values)\n",
    "\n",
    "    # Sobol åˆ†æ\n",
    "    sobol_result = sobol.analyze(problem, Y, calc_second_order=True, print_to_console=False)\n",
    "\n",
    "    # è¾“å‡ºæ–‡ä»¶åæ”¯æŒæ¨¡å‹ååŒºåˆ†\n",
    "    tag_full = f\"{tag}_model_{sanitize(str(target_model))}\" if target_model else tag\n",
    "    df_out = pd.DataFrame({\n",
    "        \"å˜é‡\": var_names,\n",
    "        \"ä¸€é˜¶S1\": np.round(sobol_result['S1'], 4),\n",
    "        \"æ€»æ•ˆST\": np.round(sobol_result['ST'], 4),\n",
    "        \"S1_conf\": np.round(sobol_result['S1_conf'], 4),\n",
    "        \"ST_conf\": np.round(sobol_result['ST_conf'], 4)\n",
    "    })\n",
    "    outpath = os.path.join(output_dir, f\"{tag_full}_sobol.csv\")\n",
    "    df_out.to_csv(outpath, index=False, encoding='utf-8-sig')\n",
    "    print(f\"[âœ”] Sobol æ€»æ•ˆåº”åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š{outpath}\")\n",
    "\n",
    "def subgroup_shap_analysis_model(var, df, output_dir, fine_tune_regions):\n",
    "    df_china = df[df['Region'].isin(fine_tune_regions)].copy()\n",
    "    model_vals = df_china[\"Model\"].unique()\n",
    "\n",
    "    for model_name in model_vals:\n",
    "        df_sub = df_china[df_china[\"Model\"] == model_name].copy()\n",
    "        if len(df_sub) < 40:\n",
    "            print(f\"[è·³è¿‡] Model={model_name} æ ·æœ¬è¿‡å°‘ï¼ˆ{len(df_sub)} æ¡ï¼‰\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"[â–¶] æ­£åœ¨åˆ†æ Model={model_name}...\")\n",
    "            sub_output = os.path.join(output_dir, f\"China_Model_{sanitize(str(model_name))}\")\n",
    "            # analyze å‡½æ•°éœ€æ”¯æŒ target_model å‚æ•°\n",
    "            analyze(var, df, sub_output, fine_tune_regions, target_model=model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"[âŒ] Model={model_name} åˆ†æå¤±è´¥ï¼š{e}\")\n",
    "\n",
    "# å¿…é¡»å®šä¹‰ sanitize å‡½æ•°ç”¨äºå‘½å\n",
    "def sanitize(s):\n",
    "    import re\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', s)\n",
    "\n",
    "# analyze å‡½æ•°å³ä¸ºä¹‹å‰ä½ ä¿®æ”¹çš„æ”¯æŒ RandomForest/target_model çš„ analyze\n",
    "\n",
    "# ç¤ºä¾‹ç”¨æ³•\n",
    "# run_sobol_analysis(X, y, var_names, output_dir, tag=\"your_tag\", target_model=\"GCAM5.3\")\n",
    "# subgroup_shap_analysis_model('å˜é‡å', df, output_dir, [\"CHN\", \"R10CHINA+\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154cdd20-0498-4c92-a9c8-bfa5890a65a7",
   "metadata": {},
   "source": [
    "# å˜é‡ä¸‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b761e6-cb38-46e2-a47b-541eaeb877a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## COFFEE 1.1\tPrimary Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34e7330-e08e-47d7-8ecd-6c417184b9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âˆš] ä»…é’ˆå¯¹æ¨¡å‹ COFFEE 1.1 è¿›è¡Œå­æ ·æœ¬åˆ†æï¼Œæ ·æœ¬é‡: 6930\n",
      "[âœ”] pe ä½¿ç”¨ RandomForest åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe_model_COFFEE 1.1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT)\n",
    "analyze('pe', df, OUTPUT_DIR, target_model='COFFEE 1.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1541385e-2468-4e0d-ba24-aa21b59691a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### å­é›†ç‰¹å¾å†è®­ç»ƒä¸éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8231875c-21c2-4b7a-bdf2-fcd1746f8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_subset(var, df, feature_subset, subset_name, output_dir, model_name=None):\n",
    "    id_cols = ['Model','Scenario','Region','Year', var]\n",
    "    df = df[id_cols + feature_subset].dropna()\n",
    "    X_all, y_all = df[feature_subset], df[var].values\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=40, max_depth=6,\n",
    "        min_samples_leaf=5, max_features=\"sqrt\",\n",
    "        random_state=42, warm_start=True\n",
    "    )\n",
    "    rf.fit(X_all, y_all)\n",
    "\n",
    "    # Step 1ï¸âƒ£ å¾®è°ƒåˆ°ä¸­å›½åŒºåŸŸ\n",
    "    mask_china = df['Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "    if mask_china.sum() > 30:\n",
    "        X_china, y_china = X_all[mask_china], y_all[mask_china]\n",
    "        rf.set_params(n_estimators=60)\n",
    "        rf.fit(X_china, y_china)\n",
    "\n",
    "    # Step 2ï¸âƒ£ å¯é€‰æ¨¡å‹å­æ ·æœ¬å¾®è°ƒ\n",
    "    if model_name:\n",
    "        mask_model = (df['Model'] == model_name)\n",
    "        if mask_model.sum() > 20:\n",
    "            X_model, y_model = X_all[mask_model], y_all[mask_model]\n",
    "            rf.set_params(n_estimators=80)\n",
    "            rf.fit(X_model, y_model)\n",
    "\n",
    "    # è¯„ä¼°\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "    metrics = {\n",
    "        \"å­é›†åç§°\": subset_name,\n",
    "        \"ç‰¹å¾æ•°é‡\": len(feature_subset),\n",
    "        \"R2_in\": r2_score(ytr, rf.predict(Xtr)),\n",
    "        \"R2_out\": r2_score(yte, rf.predict(Xte)),\n",
    "        \"EVS_out\": explained_variance_score(yte, rf.predict(Xte)),\n",
    "        \"MSE_out\": mean_squared_error(yte, rf.predict(Xte)),\n",
    "        \"MAE_out\": mean_absolute_error(yte, rf.predict(Xte)),\n",
    "        \"MedAE_out\": median_absolute_error(yte, rf.predict(Xte)),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d35904d-74b0-4e31-9cc1-18b221b212fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feats = [\"emcoen\", \"eceaip\"]\n",
    "nonlinear_feats = [\"fee\", \"see\"]\n",
    "shap_top5_feats = [\"fee\", \"see\", \"emcoen\", \"eces\", \"seen\",\"eceaip\",\"seeg\",\"fei\",\"ecese\",\"seec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47aa14e-9a91-4a9b-a11d-8b6da4625288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe\n"
     ]
    }
   ],
   "source": [
    "target_var = 'pe'\n",
    "model_name = \"COFFEE 1.1\"  # ğŸ‘ˆ ä½ ä¼ å…¥çš„æ¨¡å‹å\n",
    "outdir = os.path.join(OUTPUT_DIR, \"pe\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_subset(target_var, df, linear_feats, \"çº¿æ€§ä¸»æ•ˆå˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, nonlinear_feats, \"éçº¿æ€§äº¤äº’å˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, shap_top5_feats, \"SHAPå‰åå˜é‡\", outdir, model_name))\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df.to_csv(os.path.join(outdir, f\"{model_name}_{target_var}_å­é›†å»ºæ¨¡æ¯”è¾ƒç»“æœ.csv\"), index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345fab3d-be57-48fc-b9ca-d4c7f644876c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sobol æ¼æ–—å¼éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d59b9a5-0547-4803-81ec-ae4f6414d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Local\\Temp\\ipykernel_21308\\2532936671.py:18: DeprecationWarning: `salib.sample.saltelli` will be removed in SALib 1.5.1 Please use `salib.sample.sobol`\n",
      "  param_values = saltelli.sample(problem, 512, calc_second_order=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Sobol æ€»æ•ˆåº”åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe_model_COFFEE 1.1_sobol.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Roaming\\Python\\Python310\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\data\\var_attri_data_interp_cleaned.csv\")\n",
    "# å‡è®¾ä½ çš„å˜é‡åå« 'CO2'\n",
    "X = df[[\"fee\", \"see\"]]        # ç”¨ä½ å…³å¿ƒçš„å˜é‡\n",
    "y = df['pe']\n",
    "\n",
    "output_dir = r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\"\n",
    "var_names = [\"fee\", \"see\"]\n",
    "\n",
    "# é’ˆå¯¹æ¨¡å‹å­æ ·æœ¬\n",
    "df_gcam = df[df['Model'] == 'COFFEE 1.1']\n",
    "X_gcam = df_gcam[var_names]\n",
    "y_gcam = df_gcam['pe']\n",
    "run_sobol_analysis(X_gcam, y_gcam, var_names, output_dir, tag=\"pe\", target_model='COFFEE 1.1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ead13-2843-41d4-beb9-126a294287a9",
   "metadata": {},
   "source": [
    "### æ¨¡å‹é™ç»´&äº¤äº’å»ºæ¨¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b7b2bf-eebf-4b25-9ed8-c1a5c25dfe75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3437716-c224-429f-acb0-ac5918c93e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RFå¢é‡å¾®è°ƒæ¨¡å‹å·²åœ¨å…¨éƒ¨æ ·æœ¬å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred, prefix=\"\"):\n",
    "    return {\n",
    "        f\"{prefix}R2\": r2_score(y_true, y_pred),\n",
    "        f\"{prefix}EVS\": explained_variance_score(y_true, y_pred),\n",
    "        f\"{prefix}MSE\": mean_squared_error(y_true, y_pred),\n",
    "        f\"{prefix}MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        f\"{prefix}MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "feature_subset = ['see']\n",
    "target_var = 'pe'\n",
    "model_name = \"COFFEE 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"pe\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "X_all = df[feature_subset].dropna()\n",
    "y_all = df.loc[X_all.index, target_var]\n",
    "\n",
    "# === åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼ˆæŒ‰0.3æ¯”ä¾‹ï¼‰ ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. å¢é‡å¾®è°ƒï¼šä¸­å›½å­æ ·æœ¬ï¼Œå†åŠ 50æ£µæ ‘ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. å¢é‡å¾®è°ƒï¼šæ¨¡å‹å­æ ·æœ¬ï¼Œå†åŠ 50æ£µæ ‘ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒé›†/æµ‹è¯•é›†è¯„ä¼° ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr), prefix=\"R2_in_\")\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte), prefix=\"R2_out_\")\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2_in_R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2_out_R2\"],\n",
    "    \"EVS_out\": metrics_out[\"R2_out_EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"R2_out_MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"R2_out_MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"R2_out_MedAE\"],\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RFå¢é‡å¾®è°ƒæ¨¡å‹å·²åœ¨å…¨éƒ¨æ ·æœ¬å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8265dbd1-9614-47cd-b16a-bd1495e45ce4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### seeåˆ†æ®µ+see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df169fbf-049f-429f-b431-fe65e521b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RFåˆ†æ®µå˜é‡+seeå¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred, prefix=\"\"):\n",
    "    return {\n",
    "        f\"{prefix}R2\": r2_score(y_true, y_pred),\n",
    "        f\"{prefix}EVS\": explained_variance_score(y_true, y_pred),\n",
    "        f\"{prefix}MSE\": mean_squared_error(y_true, y_pred),\n",
    "        f\"{prefix}MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        f\"{prefix}MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === see åˆ†ä¸‰æ®µå“‘å˜é‡ ===\n",
    "see_thresh1, see_thresh2 = 25, 35\n",
    "df['see_low']  = (df['see'] <=  see_thresh1).astype(int)\n",
    "df['see_mid']  = ((df['see'] > see_thresh1) & (df['see'] <= see_thresh2)).astype(int)\n",
    "df['see_high'] = (df['see'] >  see_thresh2).astype(int)\n",
    "assert ((df[['see_low','see_mid','see_high']].sum(axis=1) == 1)).all()\n",
    "\n",
    "feature_subset = ['see_low', 'see_mid', 'see_high', 'see']\n",
    "target_var = 'pe'\n",
    "model_name = \"COFFEE 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"pe\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "X_all = df[feature_subset].dropna()\n",
    "y_all = df.loc[X_all.index, target_var]\n",
    "\n",
    "# === åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. å¢é‡å¾®è°ƒï¼šä¸­å›½å­æ ·æœ¬ï¼Œå†åŠ 50æ£µæ ‘ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. å¢é‡å¾®è°ƒï¼šæ¨¡å‹å­æ ·æœ¬ï¼Œå†åŠ 50æ£µæ ‘ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. åˆ†åˆ«è¯„ä¼°è®­ç»ƒé›†å’Œæµ‹è¯•é›† ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr), prefix=\"R2_in_\")\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte), prefix=\"R2_out_\")\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2_in_R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2_out_R2\"],\n",
    "    \"EVS_out\": metrics_out[\"R2_out_EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"R2_out_MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"R2_out_MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"R2_out_MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RFåˆ†æ®µå˜é‡+seeå¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836537c-cf58-4501-bb26-82303a404c6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### see+fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bcf51c-0666-412d-b8f7-6cc333638b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF see+fee å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "feature_subset = ['see', 'fee']\n",
    "target_var = 'pe'\n",
    "model_name = \"COFFEE 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"pe\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === éšæœºæ‹†åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒï¼Œå¢é‡åŠ æ ‘ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. æ¨¡å‹å­æ ·æœ¬å¾®è°ƒï¼Œå†å¢é‡åŠ æ ‘ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒé›†/æµ‹è¯•é›†åˆ†åˆ«è¯„ä¼° ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2\"],\n",
    "    \"EVS_out\": metrics_out[\"EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF see+fee å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225daf67-20ee-4fe1-b8eb-f9c008e0d6ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### see+fee+fee*see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593759d7-1d0f-43a4-a85f-7f46e5d55f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF see+fee+fee*see å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€ äº¤äº’é¡¹ ===\n",
    "df['fee_see'] = df['fee'] * df['see']\n",
    "\n",
    "feature_subset = ['see', 'fee', 'fee_see']\n",
    "target_var = 'pe'\n",
    "model_name = \"COFFEE 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"pe\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. æ¨¡å‹å­æ ·æœ¬å¾®è°ƒ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. åˆ†åˆ«è¯„ä¼° ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2\"],\n",
    "    \"EVS_out\": metrics_out[\"EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF see+fee+fee*see å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c866708-e865-473d-830e-39436f77f1de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### see+fee+see*seeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ba41e4-52fa-4bf0-a6f4-997a992d4ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF see+fee+see*seeh å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€ äº¤äº’é¡¹ ===\n",
    "df['see_seeh'] = df['see'] * df['seeh']\n",
    "\n",
    "feature_subset = ['see', 'fee', 'see_seeh']\n",
    "target_var = 'pe'\n",
    "model_name = \"COFFEE 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"pe\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒï¼ˆå¢é‡åŠ æ ‘ï¼‰ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. æ¨¡å‹å­æ ·æœ¬å¾®è°ƒï¼ˆå†å¢é‡åŠ æ ‘ï¼‰ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒ/æµ‹è¯•é›†åˆ†åˆ«è¯„ä¼° ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2\"],\n",
    "    \"EVS_out\": metrics_out[\"EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF see+fee+see*seeh å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa893708-dc32-4b9a-bb6c-588216da3234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### see+fee+fee*see+see*seeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a93a17-60f9-4983-9573-95c71cad8e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF see+fee+fee*see+see*seeh å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\pe\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€ äº¤äº’é¡¹ ===\n",
    "df['fee_see'] = df['fee'] * df['see']\n",
    "df['see_seeh'] = df['see'] * df['seeh']\n",
    "\n",
    "feature_subset = ['see', 'fee', 'fee_see', 'see_seeh']\n",
    "target_var = 'pe'\n",
    "model_name = \"COFFEE 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"pe\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒï¼ˆå¢é‡åŠ æ ‘ï¼‰ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. æ¨¡å‹å­æ ·æœ¬å¾®è°ƒï¼ˆå†å¢é‡åŠ æ ‘ï¼‰ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒ/æµ‹è¯•é›†åˆ†åˆ«è¯„ä¼° ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2\"],\n",
    "    \"EVS_out\": metrics_out[\"EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF see+fee+fee*see+see*seeh å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ccaaf-8a1b-4454-a9a5-f08f305e0f65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# å˜é‡äºŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b6a07-14e0-4c22-8bf8-dda3e8ebff5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## GCAM 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c533d-7aa0-44a6-8af3-519567dcade8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Final Energy|Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f554144-c3a5-4fc6-9cef-879641b275c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âˆš] ä»…é’ˆå¯¹æ¨¡å‹ GCAM 5.3 è¿›è¡Œå­æ ·æœ¬åˆ†æï¼Œæ ·æœ¬é‡: 4590\n",
      "[âœ”] fei ä½¿ç”¨ RandomForest åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei_model_GCAM 5.3\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT)\n",
    "analyze('fei', df, OUTPUT_DIR, target_model='GCAM 5.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63613d8-3fde-4269-8e90-e01d0b426ccc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### å­é›†ç‰¹å¾å†è®­ç»ƒä¸éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b3eb404-c70d-434a-8a89-2a1103b377cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_subset(var, df, feature_subset, subset_name, output_dir, model_name=None):\n",
    "    id_cols = ['Model','Scenario','Region','Year', var]\n",
    "    df = df[id_cols + feature_subset].dropna()\n",
    "    X_all, y_all = df[feature_subset], df[var].values\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=40, max_depth=6,\n",
    "        min_samples_leaf=5, max_features=\"sqrt\",\n",
    "        random_state=42, warm_start=True\n",
    "    )\n",
    "    rf.fit(X_all, y_all)\n",
    "\n",
    "    # Step 1ï¸âƒ£ å¾®è°ƒåˆ°ä¸­å›½åŒºåŸŸ\n",
    "    mask_china = df['Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "    if mask_china.sum() > 30:\n",
    "        X_china, y_china = X_all[mask_china], y_all[mask_china]\n",
    "        rf.set_params(n_estimators=60)\n",
    "        rf.fit(X_china, y_china)\n",
    "\n",
    "    # Step 2ï¸âƒ£ å¯é€‰æ¨¡å‹å­æ ·æœ¬å¾®è°ƒ\n",
    "    if model_name:\n",
    "        mask_model = (df['Model'] == model_name)\n",
    "        if mask_model.sum() > 20:\n",
    "            X_model, y_model = X_all[mask_model], y_all[mask_model]\n",
    "            rf.set_params(n_estimators=80)\n",
    "            rf.fit(X_model, y_model)\n",
    "\n",
    "    # è¯„ä¼°\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "    metrics = {\n",
    "        \"å­é›†åç§°\": subset_name,\n",
    "        \"ç‰¹å¾æ•°é‡\": len(feature_subset),\n",
    "        \"R2_in\": r2_score(ytr, rf.predict(Xtr)),\n",
    "        \"R2_out\": r2_score(yte, rf.predict(Xte)),\n",
    "        \"EVS_out\": explained_variance_score(yte, rf.predict(Xte)),\n",
    "        \"MSE_out\": mean_squared_error(yte, rf.predict(Xte)),\n",
    "        \"MAE_out\": mean_absolute_error(yte, rf.predict(Xte)),\n",
    "        \"MedAE_out\": median_absolute_error(yte, rf.predict(Xte)),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96950440-0516-4c51-b508-67e4d12a1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feats = [\"seebwoc\"]\n",
    "nonlinear_feats = [\"seec\", \"seegwoc\"]\n",
    "shap_top5_feats = [\"seec\", \"seegwoc\", \"seecwoc\", \"seebwoc\", \"eces\",\"eceaip\",\"emcoen\",\"ecese\",\"eced\",\"fel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5637a3a4-b6c4-4580-b0ba-e7ec7c4bd622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei\n"
     ]
    }
   ],
   "source": [
    "target_var = 'fei'\n",
    "model_name = \"GCAM 5.3\"  # ğŸ‘ˆ ä½ ä¼ å…¥çš„æ¨¡å‹å\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fei\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_subset(target_var, df, linear_feats, \"çº¿æ€§ä¸»æ•ˆå˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, nonlinear_feats, \"éçº¿æ€§äº¤äº’å˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, shap_top5_feats, \"SHAPå‰åå˜é‡\", outdir, model_name))\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df.to_csv(os.path.join(outdir, f\"{model_name}_{target_var}_å­é›†å»ºæ¨¡æ¯”è¾ƒç»“æœ.csv\"), index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d2028-50f1-4f9e-9ed5-3d6b8572382c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sobol æ¼æ–—å¼éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d97be9-2e38-4917-a354-55badc887519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Local\\Temp\\ipykernel_21308\\2532936671.py:18: DeprecationWarning: `salib.sample.saltelli` will be removed in SALib 1.5.1 Please use `salib.sample.sobol`\n",
      "  param_values = saltelli.sample(problem, 512, calc_second_order=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Sobol æ€»æ•ˆåº”åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei_model_GCAM 5.3_sobol.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Roaming\\Python\\Python310\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\data\\var_attri_data_interp_cleaned.csv\")\n",
    "# å‡è®¾ä½ çš„å˜é‡åå« 'CO2'\n",
    "X = df[[\"seec\", \"seegwoc\"]]        # ç”¨ä½ å…³å¿ƒçš„å˜é‡\n",
    "y = df['fei']\n",
    "\n",
    "output_dir = r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\"\n",
    "var_names = [\"seec\", \"seegwoc\"]\n",
    "\n",
    "# é’ˆå¯¹æ¨¡å‹å­æ ·æœ¬\n",
    "df_gcam = df[df['Model'] == 'GCAM 5.3']\n",
    "X_gcam = df_gcam[var_names]\n",
    "y_gcam = df_gcam['fei']\n",
    "run_sobol_analysis(X_gcam, y_gcam, var_names, output_dir, tag=\"fei\", target_model='GCAM 5.3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ea62d-9dab-4ed1-8dbe-571d8d6ce876",
   "metadata": {},
   "source": [
    "#### æ¨¡å‹é™ç»´&äº¤äº’å»ºæ¨¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384293ce-8156-40b9-b353-7279473c2089",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### seec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93c67c3f-ba70-4634-a711-c4271f9f2e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF seecâ†’fei/GCAM5.3 å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "feature_subset = ['seec']\n",
    "target_var = 'fei'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fei\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒé›†/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. GCAM 5.3 å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒ/æµ‹è¯•é›†åˆ†åˆ«è¯„ä¼°å…­é¡¹æŒ‡æ ‡ ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2\"],\n",
    "    \"EVS_out\": metrics_out[\"EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF seecâ†’fei/GCAM5.3 å¢é‡å¾®è°ƒåæ¨¡å‹å·²å®Œæˆè®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8492f13-6dda-44b9-88d4-dd87c1f3dd2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### seecåˆ†æ®µ+seec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "355f388b-d057-4360-89e5-9e5395d4c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF seecåˆ†æ®µ+seec å¢é‡å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å®Œæˆå›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === 1. ç¡®å®šåˆ†æ®µé˜ˆå€¼ ===\n",
    "seec_thresh1, seec_thresh2 = 10, 15\n",
    "\n",
    "# === 2. æ„é€ ä¸‰æ®µå“‘å˜é‡ ===\n",
    "df['seec_low']  = (df['seec'] <=  seec_thresh1).astype(int)\n",
    "df['seec_mid']  = ((df['seec'] > seec_thresh1) & (df['seec'] <= seec_thresh2)).astype(int)\n",
    "df['seec_high'] = (df['seec'] >  seec_thresh2).astype(int)\n",
    "\n",
    "# === 3. æ ¡éªŒ ===\n",
    "assert (df[['seec_low','seec_mid','seec_high']].sum(axis=1) == 1).all()\n",
    "\n",
    "feature_subset = ['seec_low', 'seec_mid', 'seec_high', 'seec']\n",
    "target_var = 'fei'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fei\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "\n",
    "# === è®­ç»ƒ/æµ‹è¯•é›†æ‹†åˆ† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. GCAM 5.3 å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒ/æµ‹è¯•é›†åˆ†åˆ«è¯„ä¼°å…­é¡¹æŒ‡æ ‡ ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2\"],\n",
    "    \"EVS_out\": metrics_out[\"EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF seecåˆ†æ®µ+seec å¢é‡å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å®Œæˆå›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7ee6f-915a-4b33-b284-166cc54627c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### seec+seegwoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e165f22-c20c-4ce1-8d07-0d8e7b2fe303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF seec+seegwoc å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å®Œæˆå›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "feature_subset = ['seec', 'seegwoc']\n",
    "target_var = 'fei'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fei\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. è®­ç»ƒé›†ä¸Šè®­ç»ƒ\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒ\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. GCAM 5.3 å­æ ·æœ¬å¾®è°ƒ\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. è¾“å‡ºè®­ç»ƒé›†ã€æµ‹è¯•é›†å…­é¡¹æŒ‡æ ‡\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":  metrics_in[\"R2\"],\n",
    "    \"R2_out\": metrics_out[\"R2\"],\n",
    "    \"EVS_out\": metrics_out[\"EVS\"],\n",
    "    \"MSE_out\": metrics_out[\"MSE\"],\n",
    "    \"MAE_out\": metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFæœ€ç»ˆå¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF seec+seegwoc å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å®Œæˆå›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ffaba1-c8b9-4f0e-ae8d-16584f8b2685",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### seec+seegwoc+seegwoc*fel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dafa2b7b-bdb4-4a77-8012-07ce917d2697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF seec+seegwoc+seegwoc*fel å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å®Œæˆå›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€ äº¤äº’é¡¹ ===\n",
    "df['seegwoc_fel'] = df['seegwoc'] * df['fel']\n",
    "\n",
    "feature_subset = ['seec', 'seegwoc', 'seegwoc_fel']\n",
    "target_var = 'fei'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fei\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. å…¨æ ·æœ¬è®­ç»ƒ\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒï¼ˆå¢é‡åŠ æ ‘ï¼‰\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. GCAM 5.3 å­æ ·æœ¬å¾®è°ƒï¼ˆå†å¢é‡åŠ æ ‘ï¼‰\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. åˆ†åˆ«è¾“å‡ºè®­ç»ƒ/æµ‹è¯•é›†æŒ‡æ ‡\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFæœ€ç»ˆå¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF seec+seegwoc+seegwoc*fel å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å®Œæˆå›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c83371-5ea5-4a74-8704-267c748f9a0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### seec+seegwoc+seec*eced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "744d58e7-df7b-4bbc-9df3-1c5ad7c075d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF seec+seegwoc+seec*eced å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€ äº¤äº’é¡¹ ===\n",
    "df['seec_eced'] = df['seec'] * df['eced']\n",
    "\n",
    "feature_subset = ['seec', 'seegwoc', 'seec_eced']\n",
    "target_var = 'fei'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fei\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. å…¨æ ·æœ¬è®­ç»ƒ\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒï¼ˆå¢åŠ 50æ£µæ ‘ï¼‰\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. GCAM 5.3 å­æ ·æœ¬å¾®è°ƒï¼ˆå†å¢åŠ 50æ£µæ ‘ï¼‰\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. è®­ç»ƒ/æµ‹è¯•é›†åˆ†åˆ«å›å½’è¯„ä¼°\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFæœ€ç»ˆå¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF seec+seegwoc+seec*eced å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3511000-bcbe-4ee6-a77e-d2a35c483e48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### seec+seegwoc+seegwoc*fel+seec*eced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb84047-13ea-429a-ad10-e7cc25f05190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF seec+seegwoc+seegwocfel+seececed å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fei\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€ äº¤äº’ç‰¹å¾ ===\n",
    "df['seegwocfel'] = df['seegwoc'] * df['fel']\n",
    "df['seececed']   = df['seec'] * df['eced']\n",
    "\n",
    "feature_subset = ['seec', 'seegwoc', 'seegwocfel', 'seececed']\n",
    "target_var = 'fei'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fei\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. å…¨æ ·æœ¬è®­ç»ƒ\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¾®è°ƒï¼ˆå¢é‡åŠ 50æ£µæ ‘ï¼‰\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. GCAM 5.3 å­æ ·æœ¬å¾®è°ƒï¼ˆå†åŠ 50æ£µæ ‘ï¼‰\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. åˆ†åˆ«è¯„ä¼°è®­ç»ƒ/æµ‹è¯•é›†\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFæœ€ç»ˆå¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF seec+seegwoc+seegwocfel+seececed å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b9a96-6a68-44e7-b48d-5bdb405c045e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Final Energy|Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c059fab8-a219-410f-882b-1001e5b66372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âˆš] ä»…é’ˆå¯¹æ¨¡å‹ GCAM 5.3 è¿›è¡Œå­æ ·æœ¬åˆ†æï¼Œæ ·æœ¬é‡: 4590\n",
      "[âœ”] fet ä½¿ç”¨ RandomForest åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fet_model_GCAM 5.3\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT)\n",
    "analyze('fet', df, OUTPUT_DIR, target_model='GCAM 5.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396af4b-348a-4673-9b8e-e41833bae44a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### å­é›†ç‰¹å¾å†è®­ç»ƒä¸éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ad245a6-854f-4a9a-b4aa-1a51633f124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_subset(var, df, feature_subset, subset_name, output_dir, model_name=None):\n",
    "    id_cols = ['Model','Scenario','Region','Year', var]\n",
    "    df = df[id_cols + feature_subset].dropna()\n",
    "    X_all, y_all = df[feature_subset], df[var].values\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=40, max_depth=6,\n",
    "        min_samples_leaf=5, max_features=\"sqrt\",\n",
    "        random_state=42, warm_start=True\n",
    "    )\n",
    "    rf.fit(X_all, y_all)\n",
    "\n",
    "    # Step 1ï¸âƒ£ å¾®è°ƒåˆ°ä¸­å›½åŒºåŸŸ\n",
    "    mask_china = df['Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "    if mask_china.sum() > 30:\n",
    "        X_china, y_china = X_all[mask_china], y_all[mask_china]\n",
    "        rf.set_params(n_estimators=60)\n",
    "        rf.fit(X_china, y_china)\n",
    "\n",
    "    # Step 2ï¸âƒ£ å¯é€‰æ¨¡å‹å­æ ·æœ¬å¾®è°ƒ\n",
    "    if model_name:\n",
    "        mask_model = (df['Model'] == model_name)\n",
    "        if mask_model.sum() > 20:\n",
    "            X_model, y_model = X_all[mask_model], y_all[mask_model]\n",
    "            rf.set_params(n_estimators=80)\n",
    "            rf.fit(X_model, y_model)\n",
    "\n",
    "    # è¯„ä¼°\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "    metrics = {\n",
    "        \"å­é›†åç§°\": subset_name,\n",
    "        \"ç‰¹å¾æ•°é‡\": len(feature_subset),\n",
    "        \"R2_in\": r2_score(ytr, rf.predict(Xtr)),\n",
    "        \"R2_out\": r2_score(yte, rf.predict(Xte)),\n",
    "        \"EVS_out\": explained_variance_score(yte, rf.predict(Xte)),\n",
    "        \"MSE_out\": mean_squared_error(yte, rf.predict(Xte)),\n",
    "        \"MAE_out\": mean_absolute_error(yte, rf.predict(Xte)),\n",
    "        \"MedAE_out\": median_absolute_error(yte, rf.predict(Xte)),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03808435-2206-42d8-a6ce-a28bbeb56e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feats = ['seeb','fel','penr','see']\n",
    "nonlinear_feats = ['feg']\n",
    "shap_top5_feats = [\"seec\", \"seegwoc\", \"seecwoc\", \"seebwoc\", \"eces\",\"eceaip\",\"emcoen\",\"ecese\",\"eced\",\"fel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1a60b62-c790-42c9-9bbe-1c8d871e3701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fet\n"
     ]
    }
   ],
   "source": [
    "target_var = 'fet'\n",
    "model_name = \"GCAM 5.3\"  # ğŸ‘ˆ ä½ ä¼ å…¥çš„æ¨¡å‹å\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fet\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_subset(target_var, df, linear_feats, \"çº¿æ€§ä¸»æ•ˆå˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, nonlinear_feats, \"éçº¿æ€§äº¤äº’å˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, shap_top5_feats, \"SHAPå‰åå˜é‡\", outdir, model_name))\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df.to_csv(os.path.join(outdir, f\"{model_name}_{target_var}_å­é›†å»ºæ¨¡æ¯”è¾ƒç»“æœ.csv\"), index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e748e5-3f56-4c67-bd89-e3030731e222",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sobol æ¼æ–—å¼éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b77e6167-13d7-4fc1-91e0-fbb121e5b836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Local\\Temp\\ipykernel_17212\\2532936671.py:18: DeprecationWarning: `salib.sample.saltelli` will be removed in SALib 1.5.1 Please use `salib.sample.sobol`\n",
      "  param_values = saltelli.sample(problem, 512, calc_second_order=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Sobol æ€»æ•ˆåº”åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fet_model_GCAM 5.3_sobol.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Roaming\\Python\\Python310\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\data\\var_attri_data_interp_cleaned.csv\")\n",
    "# å‡è®¾ä½ çš„å˜é‡åå« 'CO2'\n",
    "X = df[['feg']]        # ç”¨ä½ å…³å¿ƒçš„å˜é‡\n",
    "y = df['fet']\n",
    "\n",
    "output_dir = r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\"\n",
    "var_names = ['feg']\n",
    "\n",
    "# é’ˆå¯¹æ¨¡å‹å­æ ·æœ¬\n",
    "df_gcam = df[df['Model'] == 'GCAM 5.3']\n",
    "X_gcam = df_gcam[var_names]\n",
    "y_gcam = df_gcam['fet']\n",
    "run_sobol_analysis(X_gcam, y_gcam, var_names, output_dir, tag=\"fet\", target_model='GCAM 5.3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba884062-2eef-46ea-af83-a25e60d8365b",
   "metadata": {},
   "source": [
    "#### æ¨¡å‹é™ç»´&äº¤äº’å»ºæ¨¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e512e27-351e-44fb-b9c0-1948e1781a0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### feg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f41d98c-426b-47d4-9c6e-015d6156d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF fegâ†’fet/GCAM5.3 å¢é‡å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fet\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "feature_subset = ['feg']\n",
    "target_var = 'fet'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fet\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. å…¨æ ·æœ¬è®­ç»ƒ\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. GCAM 5.3 å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. åˆ†åˆ«è¯„ä¼°è®­ç»ƒ/æµ‹è¯•é›†\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF fegâ†’fet/GCAM5.3 å¢é‡å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ba76ee-f629-4871-b333-8079a870770f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### fegä¸‰åˆ†æ®µ+feg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "348ce173-4e1a-4c20-8816-1a5e2ba38d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF fegåˆ†æ®µ+feg/GCAM5.3 å¢é‡å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fet\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€  feg ä¸‰åˆ†æ®µå“‘å˜é‡ ===\n",
    "df['feg_low']  = (df.feg <=  8).astype(int)\n",
    "df['feg_med']  = ((df.feg > 8) & (df.feg <= 12)).astype(int)\n",
    "df['feg_high'] = (df.feg > 12).astype(int)\n",
    "assert (df[['feg_low', 'feg_med', 'feg_high']].sum(axis=1) == 1).all()\n",
    "\n",
    "feature_subset = ['feg_low', 'feg_med', 'feg_high', 'feg']\n",
    "target_var = 'fet'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fet\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. å…¨æ ·æœ¬è®­ç»ƒ\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. GCAM 5.3 å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. è¾“å‡ºè®­ç»ƒ/æµ‹è¯•é›†æŒ‡æ ‡\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå…¨æ ·æœ¬å›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF fegåˆ†æ®µ+feg/GCAM5.3 å¢é‡å¾®è°ƒåæ¨¡å‹å·²åœ¨è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3bb60-6ecc-4838-a478-a98fff5ef4a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### feg+feg*fel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c23c3a-d7f0-4823-9f9a-c06ee3fddfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF feg+feg*fel/GCAM5.3 å¢é‡å¾®è°ƒå·²åˆ†è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\fet\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€ äº¤äº’é¡¹ ===\n",
    "df['feg_fel'] = df['feg'] * df['fel']\n",
    "\n",
    "feature_subset = ['feg', 'feg_fel']\n",
    "target_var = 'fet'\n",
    "model_name = \"GCAM 5.3\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"fet\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# === åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "X = df[feature_subset].dropna()\n",
    "y = df.loc[X.index, target_var]\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. å…¨æ ·æœ¬è®­ç»ƒï¼ˆç”¨è®­ç»ƒé›†ï¼‰\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "china_mask = df.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. GCAM 5.3 å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "model_mask = (df.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. è®­ç»ƒ/æµ‹è¯•é›†è¯„ä¼°\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF feg+feg*fel/GCAM5.3 å¢é‡å¾®è°ƒå·²åˆ†è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b6cf0-ecf0-4768-8bf1-3cb93ffe44de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IMACLIM 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649620c-116e-43db-9230-3ff6172993c8",
   "metadata": {},
   "source": [
    "### Secondary Energy|Electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7089e769-531f-4cbc-af12-e101ebcff2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âˆš] ä»…é’ˆå¯¹æ¨¡å‹ IMACLIM 1.1 è¿›è¡Œå­æ ·æœ¬åˆ†æï¼Œæ ·æœ¬é‡: 6120\n",
      "[âœ”] see ä½¿ç”¨ RandomForest åˆ†æå®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see_model_IMACLIM 1.1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT)\n",
    "analyze('see', df, OUTPUT_DIR, target_model='IMACLIM 1.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847e4e9-8cf2-4fe0-8bc7-5c1d48ad37ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### å­é›†ç‰¹å¾å†è®­ç»ƒä¸éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0bf5d8c-f8ef-4325-84e8-098abf5a5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_subset(var, df, feature_subset, subset_name, output_dir, model_name=None):\n",
    "    id_cols = ['Model','Scenario','Region','Year', var]\n",
    "    df = df[id_cols + feature_subset].dropna()\n",
    "    X_all, y_all = df[feature_subset], df[var].values\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=40, max_depth=6,\n",
    "        min_samples_leaf=5, max_features=\"sqrt\",\n",
    "        random_state=42, warm_start=True\n",
    "    )\n",
    "    rf.fit(X_all, y_all)\n",
    "\n",
    "    # Step 1ï¸âƒ£ å¾®è°ƒåˆ°ä¸­å›½åŒºåŸŸ\n",
    "    mask_china = df['Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "    if mask_china.sum() > 30:\n",
    "        X_china, y_china = X_all[mask_china], y_all[mask_china]\n",
    "        rf.set_params(n_estimators=60)\n",
    "        rf.fit(X_china, y_china)\n",
    "\n",
    "    # Step 2ï¸âƒ£ å¯é€‰æ¨¡å‹å­æ ·æœ¬å¾®è°ƒ\n",
    "    if model_name:\n",
    "        mask_model = (df['Model'] == model_name)\n",
    "        if mask_model.sum() > 20:\n",
    "            X_model, y_model = X_all[mask_model], y_all[mask_model]\n",
    "            rf.set_params(n_estimators=80)\n",
    "            rf.fit(X_model, y_model)\n",
    "\n",
    "    # è¯„ä¼°\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "    metrics = {\n",
    "        \"å­é›†åç§°\": subset_name,\n",
    "        \"ç‰¹å¾æ•°é‡\": len(feature_subset),\n",
    "        \"R2_in\": r2_score(ytr, rf.predict(Xtr)),\n",
    "        \"R2_out\": r2_score(yte, rf.predict(Xte)),\n",
    "        \"EVS_out\": explained_variance_score(yte, rf.predict(Xte)),\n",
    "        \"MSE_out\": mean_squared_error(yte, rf.predict(Xte)),\n",
    "        \"MAE_out\": mean_absolute_error(yte, rf.predict(Xte)),\n",
    "        \"MedAE_out\": median_absolute_error(yte, rf.predict(Xte)),\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93a9e319-76ee-469c-b14f-6a89aea07406",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feats = ['fet','pe']\n",
    "nonlinear_feats = ['fee','penr']\n",
    "shap_top5_feats = [\"fee\", \"penr\", \"fet\", \"pe\", \"feg\",\"pen\",\"eced\",\"pegwoc\",\"fel\",\"peg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d352f5cc-3410-48d9-a180-79f3afc5a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see\n"
     ]
    }
   ],
   "source": [
    "target_var = 'see'\n",
    "model_name = \"IMACLIM 1.1\"  # ğŸ‘ˆ ä½ ä¼ å…¥çš„æ¨¡å‹å\n",
    "outdir = os.path.join(OUTPUT_DIR, \"see\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "results = []\n",
    "results.append(evaluate_subset(target_var, df, linear_feats, \"çº¿æ€§ä¸»æ•ˆå˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, nonlinear_feats, \"éçº¿æ€§äº¤äº’å˜é‡\", outdir, model_name))\n",
    "results.append(evaluate_subset(target_var, df, shap_top5_feats, \"SHAPå‰åå˜é‡\", outdir, model_name))\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df.to_csv(os.path.join(outdir, f\"{model_name}_{target_var}_å­é›†å»ºæ¨¡æ¯”è¾ƒç»“æœ.csv\"), index=False, encoding='utf-8-sig')\n",
    "print(\"âœ… å­é›†å»ºæ¨¡è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17f16d-3f33-481e-9f14-62fe9ac81bfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Sobol æ¼æ–—å¼éªŒè¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2269c4c4-1d5a-411a-8ef4-a401c1406606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Local\\Temp\\ipykernel_17212\\2532936671.py:18: DeprecationWarning: `salib.sample.saltelli` will be removed in SALib 1.5.1 Please use `salib.sample.sobol`\n",
      "  param_values = saltelli.sample(problem, 512, calc_second_order=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] Sobol æ€»æ•ˆåº”åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼šC:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see_model_IMACLIM 1.1_sobol.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Roaming\\Python\\Python310\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\data\\var_attri_data_interp_cleaned.csv\")\n",
    "# å‡è®¾ä½ çš„å˜é‡åå« 'CO2'\n",
    "X = df[['fee','penr']]        # ç”¨ä½ å…³å¿ƒçš„å˜é‡\n",
    "y = df['see']\n",
    "\n",
    "output_dir = r\"C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\"\n",
    "var_names = ['fee','penr']\n",
    "\n",
    "# é’ˆå¯¹æ¨¡å‹å­æ ·æœ¬\n",
    "df_gcam = df[df['Model'] == 'IMACLIM 1.1']\n",
    "X_gcam = df_gcam[var_names]\n",
    "y_gcam = df_gcam['see']\n",
    "run_sobol_analysis(X_gcam, y_gcam, var_names, output_dir, tag=\"see\", target_model='IMACLIM 1.1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ccda5-b60d-4554-9960-7c85aaf3a2bd",
   "metadata": {},
   "source": [
    "#### æ¨¡å‹é™ç»´&äº¤äº’å»ºæ¨¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601fcfa-5d13-4faf-937b-7d11018f9624",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78c0e7c7-8050-4740-b509-58f00e0aefcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF feeâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒåˆ†è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "feature_subset = ['fee']\n",
    "target_var = 'see'\n",
    "model_name = \"IMACLIM 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"see\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ä»…ä¿ç•™æŒ‡å®šæ¨¡å‹çš„æ•°æ®\n",
    "df_model = df[df['Model'] == model_name]\n",
    "X = df_model[feature_subset].dropna()\n",
    "y = df_model.loc[X.index, target_var]\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. è®­ç»ƒé›†ä¸Šå»ºæ¨¡\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "china_mask = df_model.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. IMACLIM 1.1 å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "model_mask = (df_model.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. è®­ç»ƒ/æµ‹è¯•é›†åˆ†æŒ‡æ ‡è¯„ä¼°\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF feeâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒåˆ†è®­ç»ƒ/æµ‹è¯•é›†å›å½’è¯„ä¼°ï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ebbbff-6786-4afd-9737-735e1e6e4d54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### fee+feeåˆ†æ®µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e751989-873d-4d12-9b09-1ac4de8ce83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF feeåˆ†æ®µ+feeâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒæ¨¡å‹åˆ†è®­ç»ƒ/æµ‹è¯•é›†è¯„ä¼°å·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# === æ„é€  fee åˆ†æ®µ ===\n",
    "df['fee_low']    = (df.fee <= 10).astype(int)\n",
    "df['fee_medium'] = ((df.fee > 10) & (df.fee <= 25)).astype(int)\n",
    "df['fee_high']   = (df.fee > 25).astype(int)\n",
    "\n",
    "feature_subset = ['fee_low', 'fee_medium', 'fee_high', 'fee']\n",
    "target_var = 'see'\n",
    "model_name = \"IMACLIM 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"see\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ä»…ä¿ç•™æŒ‡å®šæ¨¡å‹çš„æ•°æ®\n",
    "df_model = df[df['Model'] == model_name]\n",
    "X = df_model[feature_subset].dropna()\n",
    "y = df_model.loc[X.index, target_var]\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. è®­ç»ƒé›†ä¸Šå»ºæ¨¡\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "china_mask = df_model.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# 3. IMACLIM 1.1 å­æ ·æœ¬å¢é‡å¾®è°ƒ\n",
    "model_mask = (df_model.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# 4. è®­ç»ƒ/æµ‹è¯•é›†åˆ†æŒ‡æ ‡è¯„ä¼°\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF feeåˆ†æ®µ+feeâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒæ¨¡å‹åˆ†è®­ç»ƒ/æµ‹è¯•é›†è¯„ä¼°å·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1059678-e019-4b07-b9ec-a3dfc5960ac9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### fee+penr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cf6dc85-185e-42d8-85c5-63ec355c6bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF fee+penrâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒæ¨¡å‹åˆ†è®­ç»ƒ/æµ‹è¯•é›†è¯„ä¼°å·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "feature_subset = ['fee', 'penr']\n",
    "target_var = 'see'\n",
    "model_name = \"IMACLIM 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"see\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ä»…ä¿ç•™æŒ‡å®šæ¨¡å‹çš„æ•°æ®\n",
    "df_model = df[df['Model'] == model_name]\n",
    "X = df_model[feature_subset].dropna()\n",
    "y = df_model.loc[X.index, target_var]\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒ/æµ‹è¯•é›† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†å»ºæ¨¡ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "china_mask = df_model.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. IMACLIM 1.1 å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "model_mask = (df_model.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒ/æµ‹è¯•é›†è¯„ä¼°å…­é¡¹æŒ‡æ ‡ ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF fee+penrâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒæ¨¡å‹åˆ†è®­ç»ƒ/æµ‹è¯•é›†è¯„ä¼°å·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e2ccde-6ae5-465a-891e-0a5531e1ecc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### fee+penr+penr*peowoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae4b4496-be76-4ac7-a403-e39b0f6e0712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF fee+penr+penr*peowocâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒï¼Œåˆ†è®­ç»ƒ/æµ‹è¯•é›†å…­æŒ‡æ ‡å·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# æ„é€ äº¤äº’é¡¹\n",
    "df['penr_peowoc'] = df['penr'] * df['peowoc']\n",
    "\n",
    "feature_subset = ['fee', 'penr', 'penr_peowoc']\n",
    "target_var = 'see'\n",
    "model_name = \"IMACLIM 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"see\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ä»…ä¿ç•™æŒ‡å®šæ¨¡å‹çš„æ•°æ®\n",
    "df_model = df[df['Model'] == model_name]\n",
    "X = df_model[feature_subset].dropna()\n",
    "y = df_model.loc[X.index, target_var]\n",
    "\n",
    "# === è®­ç»ƒ/æµ‹è¯•é›†æ‹†åˆ† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "china_mask = df_model.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. IMACLIM 1.1 å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "model_mask = (df_model.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒé›†ã€æµ‹è¯•é›†è¯„ä¼°6é¡¹æŒ‡æ ‡ ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå›å½’ç»“æœ.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF fee+penr+penr*peowocâ†’see/IMACLIM 1.1 å¢é‡å¾®è°ƒï¼Œåˆ†è®­ç»ƒ/æµ‹è¯•é›†å…­æŒ‡æ ‡å·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913d9aa-0bff-434c-9c7c-eee73f0a226b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### fee+penr+fee*peowoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b8d972f-8730-4274-8f5f-bf0b594b5d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF fee+penr+fee*peowocâ†’see/IMACLIM 1.1 å…­é¡¹æŒ‡æ ‡è¾“å‡ºå·²å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# æ„é€ äº¤äº’é¡¹\n",
    "df['fee_peowoc'] = df['fee'] * df['peowoc']\n",
    "\n",
    "feature_subset = ['fee', 'penr', 'fee_peowoc']\n",
    "target_var = 'see'\n",
    "model_name = \"IMACLIM 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"see\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ä»…ä¿ç•™æŒ‡å®šæ¨¡å‹çš„æ•°æ®\n",
    "df_model = df[df['Model'] == model_name]\n",
    "X = df_model[feature_subset].dropna()\n",
    "y = df_model.loc[X.index, target_var]\n",
    "\n",
    "# === è®­ç»ƒ/æµ‹è¯•é›†æ‹†åˆ† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "china_mask = df_model.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. IMACLIM 1.1 å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "model_mask = (df_model.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒ/æµ‹è¯•é›†å…­é¡¹æŒ‡æ ‡è¾“å‡º ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå›å½’å…­æŒ‡æ ‡.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF fee+penr+fee*peowocâ†’see/IMACLIM 1.1 å…­é¡¹æŒ‡æ ‡è¾“å‡ºå·²å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd9327-c5e0-4b97-a4d5-1b84a0e8b192",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### fee+penr+penr*peowoc+fee*peowoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d993788-14b7-4d9b-9948-372fe61bf76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RF fee+penr+penr*peowoc+fee*peowocâ†’see/IMACLIM 1.1 å…­é¡¹æŒ‡æ ‡è¾“å‡ºå·²å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š C:\\Users\\phc\\Desktop\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ\\ä¸­å›½æ¨¡å‹æ¯”è¾ƒ2\\4_æœºå™¨å­¦ä¹ å½’å› \\RF\\model_attri\\results\\see\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    r2_score, explained_variance_score, mean_squared_error,\n",
    "    mean_absolute_error, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"EVS\": explained_variance_score(y_true, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MedAE\": median_absolute_error(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "# === åŠ è½½æ•°æ® ===\n",
    "df = pd.read_csv(INPUT, encoding='utf-8-sig')\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# æ„é€ äº¤äº’é¡¹\n",
    "df['penr_peowoc'] = df['penr'] * df['peowoc']\n",
    "df['fee_peowoc']  = df['fee']  * df['peowoc']\n",
    "\n",
    "feature_subset = ['fee', 'penr', 'penr_peowoc', 'fee_peowoc']\n",
    "target_var = 'see'\n",
    "model_name = \"IMACLIM 1.1\"\n",
    "outdir = os.path.join(OUTPUT_DIR, \"see\")\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "# ä»…åˆ†ææŒ‡å®šæ¨¡å‹\n",
    "df_model = df[df['Model'] == model_name]\n",
    "X = df_model[feature_subset].dropna()\n",
    "y = df_model.loc[X.index, target_var]\n",
    "\n",
    "# === æ‹†åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† ===\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# === 1. å…¨è®­ç»ƒé›†è®­ç»ƒ ===\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=4,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "rf.fit(Xtr, ytr)\n",
    "\n",
    "# === 2. ä¸­å›½å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "china_mask = df_model.loc[Xtr.index, 'Region'].isin([\"CHN\", \"R10CHINA+\"])\n",
    "if china_mask.sum() > 30:\n",
    "    X_china = Xtr[china_mask]\n",
    "    y_china = ytr[china_mask]\n",
    "    rf.set_params(n_estimators=150)\n",
    "    rf.fit(X_china, y_china)\n",
    "\n",
    "# === 3. IMACLIM 1.1 å­æ ·æœ¬å¢é‡å¾®è°ƒ ===\n",
    "model_mask = (df_model.loc[Xtr.index, 'Model'] == model_name)\n",
    "if model_mask.sum() > 30:\n",
    "    X_model = Xtr[model_mask]\n",
    "    y_model = ytr[model_mask]\n",
    "    rf.set_params(n_estimators=200)\n",
    "    rf.fit(X_model, y_model)\n",
    "\n",
    "# === 4. è®­ç»ƒ/æµ‹è¯•é›†å…­é¡¹æŒ‡æ ‡è¾“å‡º ===\n",
    "metrics_in  = calc_metrics(ytr, rf.predict(Xtr))\n",
    "metrics_out = calc_metrics(yte, rf.predict(Xte))\n",
    "\n",
    "summary = {\n",
    "    \"æ ·æœ¬\": \"å…¨éƒ¨\",\n",
    "    \"R2_in\":     metrics_in[\"R2\"],\n",
    "    \"R2_out\":    metrics_out[\"R2\"],\n",
    "    \"EVS_out\":   metrics_out[\"EVS\"],\n",
    "    \"MSE_out\":   metrics_out[\"MSE\"],\n",
    "    \"MAE_out\":   metrics_out[\"MAE\"],\n",
    "    \"MedAE_out\": metrics_out[\"MedAE\"],\n",
    "}\n",
    "summary_df = pd.DataFrame([summary])\n",
    "summary_df.to_csv(\n",
    "    os.path.join(outdir, f\"{target_var}_{'+'.join(feature_subset)}_RFå¢é‡å¾®è°ƒå›å½’å…­æŒ‡æ ‡.csv\"),\n",
    "    index=False,\n",
    "    encoding='utf-8-sig'\n",
    ")\n",
    "print(\"âœ… RF fee+penr+penr*peowoc+fee*peowocâ†’see/IMACLIM 1.1 å…­é¡¹æŒ‡æ ‡è¾“å‡ºå·²å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ï¼š\", outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
