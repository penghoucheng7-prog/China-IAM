{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b20dada",
   "metadata": {},
   "source": [
    "# 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0498a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from SALib.sample import sobol as sobol_sample\n",
    "from SALib.analyze import sobol\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def run_analysis(target_variable, feature_variables_s1_st, feature_pairs_s2, \n",
    "                 input_csv_path, output_dir_path, \n",
    "                 model_params, analysis_params, plot_config,\n",
    "                 model_filter,\n",
    "                 ax,\n",
    "                 heatmap_colormap=\"Reds\"):\n",
    "    \"\"\"\n",
    "    使用三阶段训练的RandomForest模型进行Sobol敏感性分析，并将S2热力图绘制在指定的子图(ax)上。\n",
    "    所有超参数通过字典传入。\n",
    "    \"\"\"\n",
    "    # ==========================================================================\n",
    "    # 1. 路径与字体配置\n",
    "    # ==========================================================================\n",
    "    input_csv = input_csv_path\n",
    "    output_dir = output_dir_path\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    matplotlib.rcParams['font.family'] = 'serif'\n",
    "    matplotlib.rcParams['font.serif'] = ['Times New Roman']\n",
    "    matplotlib.rcParams['font.sans-serif'] = ['SimSun']\n",
    "    matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "    matplotlib.rcParams['font.weight'] = 'bold'\n",
    "    matplotlib.rcParams['axes.labelweight'] = 'bold'\n",
    "    matplotlib.rcParams['axes.titleweight'] = 'bold'\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 2. 数据准备\n",
    "    # ==========================================================================\n",
    "    print(f\"--- 步骤 1/5: 正在为目标 [{target_variable.upper()}] 准备数据... ---\")\n",
    "    s1_vars = set(feature_variables_s1_st)\n",
    "    s2_vars = set(var for pair in feature_pairs_s2 for var in pair)\n",
    "    all_feature_vars = sorted(list(s1_vars.union(s2_vars)))\n",
    "    print(f\"    分析将针对以下 {len(all_feature_vars)} 个特征变量进行：{all_feature_vars}\")\n",
    "    print(f\"    正在从 {os.path.basename(input_csv)} 加载数据...\")\n",
    "    df_raw = pd.read_csv(input_csv, encoding='utf-8-sig')\n",
    "\n",
    "    df_all = df_raw[[target_variable] + all_feature_vars].dropna()\n",
    "    X_all = df_all[all_feature_vars]\n",
    "    y_all = df_all[target_variable].values\n",
    "    print(f\"    全局数据集准备完成，样本量为: {len(df_all)}\")\n",
    "\n",
    "    fine_tune_regions = analysis_params['fine_tune_regions']\n",
    "    df_china = df_raw[df_raw['Region'].isin(fine_tune_regions)][[target_variable] + all_feature_vars].dropna()\n",
    "    X_china = df_china[all_feature_vars]\n",
    "    y_china = df_china[target_variable].values\n",
    "    print(f\"    中国区域数据集准备完成，样本量为: {len(df_china)}\")\n",
    "\n",
    "    if not model_filter or model_filter not in df_raw['Model'].unique():\n",
    "        print(f\"[错误] 未提供有效的目标模型名称 '{model_filter}'，任务终止。\")\n",
    "        return\n",
    "    df_model = df_raw[df_raw['Model'] == model_filter][[target_variable] + all_feature_vars].dropna()\n",
    "    X_model = df_model[all_feature_vars]\n",
    "    y_model = df_model[target_variable].values\n",
    "    print(f\"    目标模型 '{model_filter}' 数据集准备完成，样本量为: {len(df_model)}\")\n",
    "    \n",
    "    if len(df_all) < 20 or len(df_china) < 20 or len(df_model) < 20:\n",
    "        print(f\"[警告] 存在样本量过少的数据集，跳过 [{target_variable.upper()}] 任务。\")\n",
    "        return\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 3. Sobol 敏感性分析\n",
    "    # ==========================================================================\n",
    "    print(f\"\\n--- 步骤 2/5: 正在准备 Sobol 分析... ---\")\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_all) \n",
    "    problem = {\n",
    "        'num_vars': len(all_feature_vars),\n",
    "        'names': all_feature_vars,\n",
    "        'bounds': [[0, 1]] * len(all_feature_vars)\n",
    "    }\n",
    "    \n",
    "    sobol_n_samples = analysis_params['sobol_n_samples']\n",
    "    param_values = sobol_sample.sample(problem, sobol_n_samples, calc_second_order=True)\n",
    "    print(f\"    Sobol样本生成完毕，总样本量 (N * (2D + 2)) 为: {param_values.shape[0]} 条\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 4. 三阶段模型训练与预测\n",
    "    # ==========================================================================\n",
    "    print(f\"\\n--- 步骤 3/5: 正在为 [{target_variable.upper()}] 进行三阶段模型训练... ---\")\n",
    "    X_all_scaled = scaler.transform(X_all)\n",
    "    X_china_scaled = scaler.transform(X_china)\n",
    "    X_model_scaled = scaler.transform(X_model)\n",
    "    \n",
    "    rf_base_config = model_params['rf_base_config'].copy()\n",
    "    rf_base_config['warm_start'] = True\n",
    "    model = RandomForestRegressor(**rf_base_config)\n",
    "    \n",
    "    print(f\"    第一阶段：使用全局样本训练 ({model_params['stage1_trees']}棵树)...\")\n",
    "    model.n_estimators = model_params['stage1_trees']\n",
    "    model.fit(X_all_scaled, y_all)\n",
    "\n",
    "    print(f\"    第二阶段：使用中国样本微调 (额外{model_params['stage2_trees']}棵树)...\")\n",
    "    model.n_estimators += model_params['stage2_trees']\n",
    "    model.fit(X_china_scaled, y_china)\n",
    "    \n",
    "    print(f\"    第三阶段：使用 '{model_filter}' 样本微调 (额外{model_params['stage3_trees']}棵树)...\")\n",
    "    model.n_estimators += model_params['stage3_trees']\n",
    "    model.fit(X_model_scaled, y_model)\n",
    "    print(f\"    最终模型训练完成 (总计 {model.n_estimators} 棵树)。\")\n",
    "\n",
    "    print(\"    正在使用最终模型对Sobol样本进行预测...\")\n",
    "    Y_pred = model.predict(param_values)\n",
    "    print(\"    正在计算Sobol指数...\")\n",
    "    sobol_result = sobol.analyze(problem, Y_pred, calc_second_order=True, print_to_console=False)\n",
    "    \n",
    "    s1_st_results = pd.DataFrame({\n",
    "        \"变量\": all_feature_vars,\n",
    "        \"一阶S1\": np.round(sobol_result['S1'], 4),\n",
    "        \"总效ST\": np.round(sobol_result['ST'], 4),\n",
    "    }).sort_values(by=\"总效ST\", ascending=False)\n",
    "    \n",
    "    s1_st_filename = f\"{target_variable}_model_{model_filter.replace(' ', '_').replace('.', '')}_S1_ST.csv\"\n",
    "    s1_st_path = os.path.join(output_dir, s1_st_filename)\n",
    "    s1_st_results.to_csv(s1_st_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"[✔] S1 和 ST 指数已保存至: {s1_st_path}\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 5. S2 交互效应分析与热力图可视化\n",
    "    # ==========================================================================\n",
    "    print(f\"\\n--- 步骤 4/5: 正在为 [{target_variable.upper()}] 处理 S2 指数并生成热力图... ---\")\n",
    "    s2_matrix = sobol_result['S2']\n",
    "    var_names = problem['names']\n",
    "    s2_df = pd.DataFrame(s2_matrix, index=var_names, columns=var_names)\n",
    "    s2_values = []\n",
    "    for pair in feature_pairs_s2:\n",
    "        v1, v2 = sorted(pair)\n",
    "        s2_val = s2_df.loc[v1, v2]\n",
    "        s2_values.append({\"特征对\": f\"{v1} & {v2}\", \"S2指数\": s2_val})\n",
    "    if not s2_values:\n",
    "        print(\"[!] 未指定有效的S2特征对，跳过S2可视化。\")\n",
    "    else:\n",
    "        s2_paired_results = pd.DataFrame(s2_values).sort_values(by=\"S2指数\", ascending=False)\n",
    "        s2_csv_filename = f\"{target_variable}_model_{model_filter.replace(' ', '_').replace('.', '')}_S2_pairs.csv\"\n",
    "        s2_csv_path = os.path.join(output_dir, s2_csv_filename)\n",
    "        s2_paired_results.to_csv(s2_csv_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"[✔] 指定特征对的 S2 指数已保存至: {s2_csv_path}\")\n",
    "        \n",
    "        unique_s2_vars = sorted(list(set(var for pair in feature_pairs_s2 for var in pair)))\n",
    "        s2_heatmap_df = pd.DataFrame(np.nan, index=unique_s2_vars, columns=unique_s2_vars)\n",
    "        for var1, var2 in feature_pairs_s2:\n",
    "            v1_s, v2_s = sorted((var1, var2))\n",
    "            s2_val = s2_df.loc[v1_s, v2_s]\n",
    "            s2_heatmap_df.loc[var1, var2] = s2_val\n",
    "            s2_heatmap_df.loc[var2, var1] = s2_val\n",
    "        \n",
    "        sns.heatmap(\n",
    "            s2_heatmap_df, cmap=heatmap_colormap, annot=True, fmt=\".4f\",\n",
    "            linewidths=.5, annot_kws={'size': plot_config['annot_fontsize'], \n",
    "                                      'fontweight': 'bold'},\n",
    "            cbar_kws={'label': ''}, ax=ax\n",
    "        )\n",
    "        \n",
    "        title_text = f\"{model_filter} - {target_variable.upper()}\"\n",
    "        ax.set_title(title_text, fontsize=plot_config['title_fontsize'])\n",
    "        \n",
    "        ax.tick_params(axis='x', labelsize=plot_config['tick_label_fontsize'], labelrotation=45)\n",
    "        ax.tick_params(axis='y', labelsize=plot_config['tick_label_fontsize'], labelrotation=0)\n",
    "        \n",
    "        for label in ax.get_xticklabels(): label.set_fontweight('bold')\n",
    "        for label in ax.get_yticklabels(): label.set_fontweight('bold')\n",
    "\n",
    "        cbar = ax.collections[0].colorbar\n",
    "        \n",
    "        # --- 修改点: 移除了颜色条标题 ---\n",
    "        # cbar.set_label('S2 Index', fontsize=plot_config['cbar_label_fontsize'])\n",
    "        \n",
    "        cbar.ax.tick_params(labelsize=plot_config['cbar_tick_fontsize'])\n",
    "        for label in cbar.ax.get_yticklabels():\n",
    "            label.set_fontweight('bold')\n",
    "    \n",
    "    print(f\"    绘图完成: [{target_variable.upper()}]\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cc16b",
   "metadata": {},
   "source": [
    "# 运行区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ea2e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== 开始分析任务 1/3: 目标 FEI | 模型 GCAM 5.3 ==============================\n",
      "--- 步骤 1/5: 正在为目标 [FEI] 准备数据... ---\n",
      "    分析将针对以下 5 个特征变量进行：['eced', 'fel', 'seebwoc', 'seec', 'seegwoc']\n",
      "    正在从 变量归因_模型归因数据库.csv 加载数据...\n",
      "    全局数据集准备完成，样本量为: 25479\n",
      "    中国区域数据集准备完成，样本量为: 2547\n",
      "    目标模型 'GCAM 5.3' 数据集准备完成，样本量为: 4590\n",
      "\n",
      "--- 步骤 2/5: 正在准备 Sobol 分析... ---\n",
      "    Sobol样本生成完毕，总样本量 (N * (2D + 2)) 为: 393216 条\n",
      "\n",
      "--- 步骤 3/5: 正在为 [FEI] 进行三阶段模型训练... ---\n",
      "    第一阶段：使用全局样本训练 (40棵树)...\n",
      "    第二阶段：使用中国样本微调 (额外20棵树)...\n",
      "    第三阶段：使用 'GCAM 5.3' 样本微调 (额外20棵树)...\n",
      "    最终模型训练完成 (总计 80 棵树)。\n",
      "    正在使用最终模型对Sobol样本进行预测...\n",
      "    正在计算Sobol指数...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Roaming\\Python\\Python310\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] S1 和 ST 指数已保存至: C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\\fei_model_GCAM_53_S1_ST.csv\n",
      "\n",
      "--- 步骤 4/5: 正在为 [FEI] 处理 S2 指数并生成热力图... ---\n",
      "[✔] 指定特征对的 S2 指数已保存至: C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\\fei_model_GCAM_53_S2_pairs.csv\n",
      "    绘图完成: [FEI]\n",
      "\n",
      "============================== 开始分析任务 2/3: 目标 FET | 模型 GCAM 5.3 ==============================\n",
      "--- 步骤 1/5: 正在为目标 [FET] 准备数据... ---\n",
      "    分析将针对以下 4 个特征变量进行：['feg', 'fel', 'seeb', 'sees']\n",
      "    正在从 变量归因_模型归因数据库.csv 加载数据...\n",
      "    全局数据集准备完成，样本量为: 25479\n",
      "    中国区域数据集准备完成，样本量为: 2547\n",
      "    目标模型 'GCAM 5.3' 数据集准备完成，样本量为: 4590\n",
      "\n",
      "--- 步骤 2/5: 正在准备 Sobol 分析... ---\n",
      "    Sobol样本生成完毕，总样本量 (N * (2D + 2)) 为: 327680 条\n",
      "\n",
      "--- 步骤 3/5: 正在为 [FET] 进行三阶段模型训练... ---\n",
      "    第一阶段：使用全局样本训练 (40棵树)...\n",
      "    第二阶段：使用中国样本微调 (额外20棵树)...\n",
      "    第三阶段：使用 'GCAM 5.3' 样本微调 (额外20棵树)...\n",
      "    最终模型训练完成 (总计 80 棵树)。\n",
      "    正在使用最终模型对Sobol样本进行预测...\n",
      "    正在计算Sobol指数...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Roaming\\Python\\Python310\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] S1 和 ST 指数已保存至: C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\\fet_model_GCAM_53_S1_ST.csv\n",
      "\n",
      "--- 步骤 4/5: 正在为 [FET] 处理 S2 指数并生成热力图... ---\n",
      "[✔] 指定特征对的 S2 指数已保存至: C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\\fet_model_GCAM_53_S2_pairs.csv\n",
      "    绘图完成: [FET]\n",
      "\n",
      "============================== 开始分析任务 3/3: 目标 PE | 模型 COFFEE 1.1 ==============================\n",
      "--- 步骤 1/5: 正在为目标 [PE] 准备数据... ---\n",
      "    分析将针对以下 4 个特征变量进行：['emcoen', 'fee', 'see', 'seeh']\n",
      "    正在从 变量归因_模型归因数据库.csv 加载数据...\n",
      "    全局数据集准备完成，样本量为: 25479\n",
      "    中国区域数据集准备完成，样本量为: 2547\n",
      "    目标模型 'COFFEE 1.1' 数据集准备完成，样本量为: 6930\n",
      "\n",
      "--- 步骤 2/5: 正在准备 Sobol 分析... ---\n",
      "    Sobol样本生成完毕，总样本量 (N * (2D + 2)) 为: 327680 条\n",
      "\n",
      "--- 步骤 3/5: 正在为 [PE] 进行三阶段模型训练... ---\n",
      "    第一阶段：使用全局样本训练 (40棵树)...\n",
      "    第二阶段：使用中国样本微调 (额外20棵树)...\n",
      "    第三阶段：使用 'COFFEE 1.1' 样本微调 (额外20棵树)...\n",
      "    最终模型训练完成 (总计 80 棵树)。\n",
      "    正在使用最终模型对Sobol样本进行预测...\n",
      "    正在计算Sobol指数...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phc\\AppData\\Roaming\\Python\\Python310\\site-packages\\SALib\\util\\__init__.py:274: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  names = list(pd.unique(groups))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] S1 和 ST 指数已保存至: C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\\pe_model_COFFEE_11_S1_ST.csv\n",
      "\n",
      "--- 步骤 4/5: 正在为 [PE] 处理 S2 指数并生成热力图... ---\n",
      "[✔] 指定特征对的 S2 指数已保存至: C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\\pe_model_COFFEE_11_S2_pairs.csv\n",
      "    绘图完成: [PE]\n",
      "\n",
      "[✔] 所有分析和绘图完成，正在保存最终组合图...\n",
      "[✔] 组合图已成功保存至: C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\\Combined_RF_Sobol_Analysis_All_Targets.png\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 主程序执行区 (Main Execution Area)\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    input_file = r\"C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\data\\变量归因_模型归因数据库.csv\"\n",
    "    output_folder = r\"C:\\Users\\phc\\Desktop\\中国模型比较\\中国模型比较2\\4_机器学习归因\\RF\\model_attri\\results\\RF验证优化\"\n",
    "\n",
    "    analysis_hyperparams = {\n",
    "        'sobol_n_samples': 32768,\n",
    "        'fine_tune_regions': [\"CHN\", \"R10CHINA+\"]\n",
    "    }\n",
    "    model_hyperparams = {\n",
    "        'stage1_trees': 40, 'stage2_trees': 20, 'stage3_trees': 20,\n",
    "        'rf_base_config': {\n",
    "            'max_depth': 8, 'min_samples_leaf': 4, 'max_features': \"sqrt\",\n",
    "            'random_state': 42, 'n_jobs': -1\n",
    "        }\n",
    "    }\n",
    "    plotting_parameters = {\n",
    "        'figure_size': (20, 9), 'title_fontsize': 44, 'annot_fontsize': 45,\n",
    "        'tick_label_fontsize': 45, 'cbar_label_fontsize': 35, 'cbar_tick_fontsize': 30\n",
    "    }\n",
    "\n",
    "    analyses_to_run = [\n",
    "        {\"target\": \"fei\", \"model_filter\": \"GCAM 5.3\", \"features_for_s1_st\": [\"seebwoc\", \"seec\", \"seegwoc\"], \"features_for_s2\": [(\"seebwoc\", \"eced\"), (\"seec\", \"eced\"), (\"seegwoc\", \"fel\")], \"color_theme\": \"Greens\", \"subplot_label\": \"a\"},\n",
    "        {\"target\": \"fet\", \"model_filter\": \"GCAM 5.3\", \"features_for_s1_st\": [\"feg\", \"fel\", \"seeb\"], \"features_for_s2\": [(\"feg\", \"fel\"), (\"fel\", \"sees\"), (\"seeb\", \"feg\")], \"color_theme\": \"Reds\", \"subplot_label\": \"b\"},\n",
    "        {\"target\": \"pe\", \"model_filter\": \"COFFEE 1.1\", \"features_for_s1_st\": [\"emcoen\", \"fee\", \"see\"], \"features_for_s2\": [(\"emcoen\", \"fee\"), (\"fee\", \"see\"), (\"see\", \"seeh\")], \"color_theme\": \"Purples\", \"subplot_label\": \"c\"}\n",
    "    ]\n",
    "    \n",
    "    num_analyses = len(analyses_to_run)\n",
    "    fig, axes = plt.subplots(nrows=num_analyses, ncols=1, figsize=(24, 12 * num_analyses))\n",
    "    if num_analyses == 1: axes = [axes]\n",
    "\n",
    "    for i, config in enumerate(analyses_to_run):\n",
    "        print(f\"\\n{'='*30} 开始分析任务 {i+1}/{num_analyses}: 目标 {config['target'].upper()} | 模型 {config['model_filter']} {'='*30}\")\n",
    "        \n",
    "        run_analysis(\n",
    "            target_variable=config['target'],\n",
    "            feature_variables_s1_st=config['features_for_s1_st'],\n",
    "            feature_pairs_s2=config['features_for_s2'],\n",
    "            input_csv_path=input_file,\n",
    "            output_dir_path=output_folder,\n",
    "            model_filter=config['model_filter'],\n",
    "            ax=axes[i],\n",
    "            heatmap_colormap=config['color_theme'],\n",
    "            analysis_params=analysis_hyperparams,\n",
    "            model_params=model_hyperparams,\n",
    "            plot_config=plotting_parameters\n",
    "        )\n",
    "        \n",
    "        axes[i].text(-0.1, 1.1, config['subplot_label'], \n",
    "                     transform=axes[i].transAxes,\n",
    "                     fontsize=40, fontweight='bold', va='top', ha='left')\n",
    "\n",
    "    print(\"\\n[✔] 所有分析和绘图完成，正在保存最终组合图...\")\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    \n",
    "    final_image_path = os.path.join(output_folder, \"Combined_RF_Sobol_Analysis_All_Targets.png\")\n",
    "    plt.savefig(final_image_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[✔] 组合图已成功保存至: {final_image_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whqtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
